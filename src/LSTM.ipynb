{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU,LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../datasets/PSD45.csv').iloc[:,1:33]\n",
    "labels=pd.read_csv('../datasets/Labels.csv').iloc[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F3</th>\n",
       "      <th>F7</th>\n",
       "      <th>FC5</th>\n",
       "      <th>FC1</th>\n",
       "      <th>C3</th>\n",
       "      <th>T7</th>\n",
       "      <th>CP5</th>\n",
       "      <th>CP1</th>\n",
       "      <th>...</th>\n",
       "      <th>FC2</th>\n",
       "      <th>Cz</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>CP6</th>\n",
       "      <th>CP2</th>\n",
       "      <th>P4</th>\n",
       "      <th>P8</th>\n",
       "      <th>PO4</th>\n",
       "      <th>O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.331383</td>\n",
       "      <td>0.302093</td>\n",
       "      <td>0.134594</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.204260</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>0.226679</td>\n",
       "      <td>0.312170</td>\n",
       "      <td>0.315429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296733</td>\n",
       "      <td>0.143684</td>\n",
       "      <td>0.390341</td>\n",
       "      <td>0.546754</td>\n",
       "      <td>0.816526</td>\n",
       "      <td>0.353447</td>\n",
       "      <td>0.416153</td>\n",
       "      <td>0.209551</td>\n",
       "      <td>0.112324</td>\n",
       "      <td>0.584553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.256327</td>\n",
       "      <td>0.093801</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.332835</td>\n",
       "      <td>0.160808</td>\n",
       "      <td>0.244056</td>\n",
       "      <td>0.422417</td>\n",
       "      <td>0.117003</td>\n",
       "      <td>0.411794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322102</td>\n",
       "      <td>0.828927</td>\n",
       "      <td>0.391170</td>\n",
       "      <td>0.090605</td>\n",
       "      <td>0.150150</td>\n",
       "      <td>0.887933</td>\n",
       "      <td>0.467302</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.480559</td>\n",
       "      <td>0.412893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311773</td>\n",
       "      <td>0.392808</td>\n",
       "      <td>0.322142</td>\n",
       "      <td>0.378091</td>\n",
       "      <td>0.162233</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.632373</td>\n",
       "      <td>0.708174</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.416871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331855</td>\n",
       "      <td>1.011100</td>\n",
       "      <td>0.453283</td>\n",
       "      <td>0.292421</td>\n",
       "      <td>0.394736</td>\n",
       "      <td>0.388968</td>\n",
       "      <td>0.122635</td>\n",
       "      <td>1.107560</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.253671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.165655</td>\n",
       "      <td>0.255653</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.348375</td>\n",
       "      <td>0.721522</td>\n",
       "      <td>0.412234</td>\n",
       "      <td>0.100055</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>1.006885</td>\n",
       "      <td>0.485257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436905</td>\n",
       "      <td>0.289155</td>\n",
       "      <td>0.158386</td>\n",
       "      <td>0.895881</td>\n",
       "      <td>0.212445</td>\n",
       "      <td>0.117028</td>\n",
       "      <td>0.350288</td>\n",
       "      <td>0.498311</td>\n",
       "      <td>0.421862</td>\n",
       "      <td>0.171673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256001</td>\n",
       "      <td>0.636777</td>\n",
       "      <td>0.134918</td>\n",
       "      <td>0.462233</td>\n",
       "      <td>1.061191</td>\n",
       "      <td>0.529741</td>\n",
       "      <td>0.275045</td>\n",
       "      <td>0.412421</td>\n",
       "      <td>0.402623</td>\n",
       "      <td>0.112826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347010</td>\n",
       "      <td>0.110870</td>\n",
       "      <td>0.572758</td>\n",
       "      <td>0.477297</td>\n",
       "      <td>0.302808</td>\n",
       "      <td>0.353191</td>\n",
       "      <td>0.420857</td>\n",
       "      <td>0.401010</td>\n",
       "      <td>0.136428</td>\n",
       "      <td>0.438557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57595</th>\n",
       "      <td>0.208354</td>\n",
       "      <td>5.899343</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>2.303209</td>\n",
       "      <td>0.865383</td>\n",
       "      <td>13.545904</td>\n",
       "      <td>0.952523</td>\n",
       "      <td>1.426254</td>\n",
       "      <td>11.053223</td>\n",
       "      <td>...</td>\n",
       "      <td>41.810952</td>\n",
       "      <td>7.126157</td>\n",
       "      <td>0.473278</td>\n",
       "      <td>0.446589</td>\n",
       "      <td>4.063789</td>\n",
       "      <td>1.143567</td>\n",
       "      <td>0.385316</td>\n",
       "      <td>7.531276</td>\n",
       "      <td>2.832202</td>\n",
       "      <td>0.637985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57596</th>\n",
       "      <td>0.428503</td>\n",
       "      <td>5.576647</td>\n",
       "      <td>9.890570</td>\n",
       "      <td>1.496358</td>\n",
       "      <td>6.629244</td>\n",
       "      <td>2.367740</td>\n",
       "      <td>0.573862</td>\n",
       "      <td>2.181876</td>\n",
       "      <td>2.941306</td>\n",
       "      <td>1.286554</td>\n",
       "      <td>...</td>\n",
       "      <td>6.574940</td>\n",
       "      <td>1.157410</td>\n",
       "      <td>236.302717</td>\n",
       "      <td>3.790158</td>\n",
       "      <td>0.969567</td>\n",
       "      <td>0.677345</td>\n",
       "      <td>4.711672</td>\n",
       "      <td>41.231050</td>\n",
       "      <td>3.268565</td>\n",
       "      <td>16.743982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57597</th>\n",
       "      <td>2.349644</td>\n",
       "      <td>1.666489</td>\n",
       "      <td>0.866412</td>\n",
       "      <td>40.515346</td>\n",
       "      <td>4.597316</td>\n",
       "      <td>0.415907</td>\n",
       "      <td>0.753588</td>\n",
       "      <td>4.249526</td>\n",
       "      <td>1.418109</td>\n",
       "      <td>0.421669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117740</td>\n",
       "      <td>1.573215</td>\n",
       "      <td>1.764416</td>\n",
       "      <td>0.591828</td>\n",
       "      <td>0.197271</td>\n",
       "      <td>5.995950</td>\n",
       "      <td>0.558259</td>\n",
       "      <td>0.308661</td>\n",
       "      <td>2.478292</td>\n",
       "      <td>1.161655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57598</th>\n",
       "      <td>8.478914</td>\n",
       "      <td>0.946635</td>\n",
       "      <td>1.253631</td>\n",
       "      <td>4.861493</td>\n",
       "      <td>1.304811</td>\n",
       "      <td>134.234555</td>\n",
       "      <td>3.838969</td>\n",
       "      <td>1.141114</td>\n",
       "      <td>0.535277</td>\n",
       "      <td>3.653305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386376</td>\n",
       "      <td>20.073992</td>\n",
       "      <td>3.009233</td>\n",
       "      <td>0.736745</td>\n",
       "      <td>0.392250</td>\n",
       "      <td>4.558863</td>\n",
       "      <td>14.405906</td>\n",
       "      <td>3.604771</td>\n",
       "      <td>7.266194</td>\n",
       "      <td>2.578681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599</th>\n",
       "      <td>0.996751</td>\n",
       "      <td>1.940129</td>\n",
       "      <td>5.838806</td>\n",
       "      <td>1.722998</td>\n",
       "      <td>2.303987</td>\n",
       "      <td>2.343632</td>\n",
       "      <td>0.717226</td>\n",
       "      <td>0.261740</td>\n",
       "      <td>4.860595</td>\n",
       "      <td>0.881358</td>\n",
       "      <td>...</td>\n",
       "      <td>8.144283</td>\n",
       "      <td>35.793930</td>\n",
       "      <td>2.485796</td>\n",
       "      <td>22.043345</td>\n",
       "      <td>2.206216</td>\n",
       "      <td>1.583250</td>\n",
       "      <td>0.813395</td>\n",
       "      <td>32.607247</td>\n",
       "      <td>4.033659</td>\n",
       "      <td>0.315258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57600 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fp1       AF3        F3         F7       FC5         FC1  \\\n",
       "0      0.331383  0.302093  0.134594   1.026736  0.467752    0.204260   \n",
       "1      0.256327  0.093801  0.209467   0.520343  0.332835    0.160808   \n",
       "2      0.311773  0.392808  0.322142   0.378091  0.162233    0.311832   \n",
       "3      0.165655  0.255653  0.437500   0.348375  0.721522    0.412234   \n",
       "4      0.256001  0.636777  0.134918   0.462233  1.061191    0.529741   \n",
       "...         ...       ...       ...        ...       ...         ...   \n",
       "57595  0.208354  5.899343  0.786404   0.156360  2.303209    0.865383   \n",
       "57596  0.428503  5.576647  9.890570   1.496358  6.629244    2.367740   \n",
       "57597  2.349644  1.666489  0.866412  40.515346  4.597316    0.415907   \n",
       "57598  8.478914  0.946635  1.253631   4.861493  1.304811  134.234555   \n",
       "57599  0.996751  1.940129  5.838806   1.722998  2.303987    2.343632   \n",
       "\n",
       "              C3        T7       CP5        CP1  ...        FC2         Cz  \\\n",
       "0       0.175026  0.226679  0.312170   0.315429  ...   0.296733   0.143684   \n",
       "1       0.244056  0.422417  0.117003   0.411794  ...   0.322102   0.828927   \n",
       "2       0.632373  0.708174  0.366250   0.416871  ...   0.331855   1.011100   \n",
       "3       0.100055  0.176210  1.006885   0.485257  ...   0.436905   0.289155   \n",
       "4       0.275045  0.412421  0.402623   0.112826  ...   0.347010   0.110870   \n",
       "...          ...       ...       ...        ...  ...        ...        ...   \n",
       "57595  13.545904  0.952523  1.426254  11.053223  ...  41.810952   7.126157   \n",
       "57596   0.573862  2.181876  2.941306   1.286554  ...   6.574940   1.157410   \n",
       "57597   0.753588  4.249526  1.418109   0.421669  ...   1.117740   1.573215   \n",
       "57598   3.838969  1.141114  0.535277   3.653305  ...   0.386376  20.073992   \n",
       "57599   0.717226  0.261740  4.860595   0.881358  ...   8.144283  35.793930   \n",
       "\n",
       "               C4         T8       CP6       CP2         P4         P8  \\\n",
       "0        0.390341   0.546754  0.816526  0.353447   0.416153   0.209551   \n",
       "1        0.391170   0.090605  0.150150  0.887933   0.467302   0.167608   \n",
       "2        0.453283   0.292421  0.394736  0.388968   0.122635   1.107560   \n",
       "3        0.158386   0.895881  0.212445  0.117028   0.350288   0.498311   \n",
       "4        0.572758   0.477297  0.302808  0.353191   0.420857   0.401010   \n",
       "...           ...        ...       ...       ...        ...        ...   \n",
       "57595    0.473278   0.446589  4.063789  1.143567   0.385316   7.531276   \n",
       "57596  236.302717   3.790158  0.969567  0.677345   4.711672  41.231050   \n",
       "57597    1.764416   0.591828  0.197271  5.995950   0.558259   0.308661   \n",
       "57598    3.009233   0.736745  0.392250  4.558863  14.405906   3.604771   \n",
       "57599    2.485796  22.043345  2.206216  1.583250   0.813395  32.607247   \n",
       "\n",
       "            PO4         O2  \n",
       "0      0.112324   0.584553  \n",
       "1      0.480559   0.412893  \n",
       "2      0.664384   0.253671  \n",
       "3      0.421862   0.171673  \n",
       "4      0.136428   0.438557  \n",
       "...         ...        ...  \n",
       "57595  2.832202   0.637985  \n",
       "57596  3.268565  16.743982  \n",
       "57597  2.478292   1.161655  \n",
       "57598  7.266194   2.578681  \n",
       "57599  4.033659   0.315258  \n",
       "\n",
       "[57600 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.10</td>\n",
       "      <td>7.31</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.58</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.94</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.96</td>\n",
       "      <td>3.92</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>3.91</td>\n",
       "      <td>6.96</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2.81</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>3.05</td>\n",
       "      <td>7.01</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>3.99</td>\n",
       "      <td>7.17</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Valence  Arousal  Dominance\n",
       "0        7.71     7.60       6.90\n",
       "1        8.10     7.31       7.28\n",
       "2        8.58     7.54       9.00\n",
       "3        4.94     6.01       6.12\n",
       "4        6.96     3.92       7.19\n",
       "...       ...      ...        ...\n",
       "1275     3.91     6.96       5.82\n",
       "1276     2.81     6.13       6.06\n",
       "1277     3.05     7.01       5.10\n",
       "1278     3.99     7.17       4.85\n",
       "1279     7.15     4.03       9.00\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols=['Fp1','F3','F7','C3','T7','CP5','P3','O1','Fp2','F8','T8']\n",
    "cols=data.columns\n",
    "scaler=StandardScaler()\n",
    "scaled_data=pd.DataFrame(scaler.fit_transform(data[cols]),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_labels=labels>=5\n",
    "encoder=LabelEncoder()\n",
    "encoded_labels=[]\n",
    "encoded_labels.append(encoder.fit_transform(scaled_labels.iloc[:,0]))# 0 for valence and 1 for arousal\n",
    "encoded_labels=pd.DataFrame(np.array(encoded_labels).transpose(),columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data=scaled_data.to_numpy().reshape(1280,45,32)\n",
    "encoded_labels = to_categorical(encoded_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(256,activation='sigmoid',input_shape=(45,32)))\n",
    "  model.add(Dense(8, LeakyReLU(alpha=0.3)))\n",
    "  model.add(Dense(2, 'softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_index,test_index,fold):\n",
    "    X_train, X_test = scaled_data[train_index], scaled_data[test_index]\n",
    "    y_train, y_test = encoded_labels[train_index], encoded_labels[test_index]\n",
    "    model=create_model()\n",
    "    model.compile(loss=categorical_crossentropy,optimizer=Adam(learning_rate=0.001),metrics=[Accuracy()])\n",
    "    model.fit(X_train,y_train,epochs=150)\n",
    "    model.save(f'../model_saves/LSTM/PSD/model_valence/model_thread_{fold}')\n",
    "    result=model.predict(X_test)\n",
    "    new_result=[]\n",
    "    for i in (result):\n",
    "        new_result.append(np.where(i==i.max())[0])\n",
    "    new_result=np.array(new_result).flatten()\n",
    "    new_y=[]\n",
    "    for i in (y_test):\n",
    "        new_y.append(np.where(i==i.max())[0])\n",
    "    new_y=np.array(new_y).flatten()\n",
    "    accuracy = accuracy_score(new_y,new_result)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indra\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\indra\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "Epoch 1/150\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 232ms/step - accuracy: 0.0000e+00 - loss: 0.6912\n",
      "Epoch 2/150\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 286ms/step - accuracy: 0.0000e+00 - loss: 0.7000\n",
      "Epoch 2/150\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 303ms/step - accuracy: 0.0000e+00 - loss: 0.7083\n",
      "Epoch 2/150\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 311ms/step - accuracy: 0.0000e+00 - loss: 0.7028\n",
      "Epoch 2/150\n",
      "\u001b[1m18/39\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 675ms/step - accuracy: 0.0000e+00 - loss: 0.6759"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=32,shuffle=False)\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    fold=0\n",
    "    for train_index, test_index in k_fold.split(scaled_data):\n",
    "        fold+=1\n",
    "        futures.append(executor.submit(train_and_evaluate, train_index, test_index, fold))\n",
    "    results = [future.result() for future in futures]\n",
    "\n",
    "print(\"Cross-validation accuracies:\", results)\n",
    "print(\"Mean accuracy:\", np.mean(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
